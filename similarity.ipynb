{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import gzip\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "\n",
    "## paths to files. Do not change this\n",
    "simInputFile = \"Q1/word-similarity-dataset\"\n",
    "#analogyInputFile = \"Q1/word-analogy-dataset\"\n",
    "analogyInputFile = \"analogy_small.txt\"\n",
    "vectorgzipFile = \"Q1/glove.6B.300d.txt.gz\"\n",
    "#vectorTxtFile = \"Q1/glove.6B.300d.txt\"   # If you extract and use the gz file, use this.\n",
    "analogyTrainPath = \"Q1/wordRep/\"\n",
    "simOutputFile = \"Q1/simOutput.csv\"\n",
    "simSummaryFile = \"Q1/simSummary.csv\"\n",
    "anaSOln = \"Q1/analogySolution.csv\"\n",
    "Q4List = \"Q4/wordList.csv\"\n",
    "\n",
    "random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Similarity Dataset\n",
    "simDataset = [item.split(\" | \") for item in open(simInputFile).read().splitlines()]\n",
    "# Analogy dataset\n",
    "analogyDataset = [[stuff.strip() for stuff in item.strip('\\n').split('\\n')] for item in open(analogyInputFile).read().split('\\n\\n')]\n",
    "\n",
    "def vectorExtract(simD = simDataset, anaD = analogyDataset, vect = vectorgzipFile):\n",
    "    simList = [stuff for item in simD for stuff in item]\n",
    "    analogyList = [thing for item in anaD for stuff in item[0:4] for thing in stuff.split()]\n",
    "    #simList.extend(analogyList)\n",
    "    wordList = set(simList)\n",
    "    print(len(wordList))\n",
    "    wordDict = dict()\n",
    "    \n",
    "    vectorFile = gzip.open(vect, 'r')\n",
    "    for line in vectorFile:\n",
    "        if line.split()[0].strip().decode(\"utf-8\") in wordList:\n",
    "            wordDict[line.split()[0].strip().decode('utf-8')] = line.split()[1:]\n",
    "    \n",
    "    \n",
    "    vectorFile.close()\n",
    "    print('retrieved', len(wordDict.keys()))\n",
    "    return wordDict, simList\n",
    "\n",
    "# Extracting Vectors from Analogy and Similarity Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n",
      "retrieved 166\n"
     ]
    }
   ],
   "source": [
    "worddict, simlist = vectorExtract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rusty', 'corroded', 'black', 'dirty', 'painted', 'brass', 'metal', 'wood', 'stone', 'plastic', 'spin', 'twirl', 'ache', 'sweat', 'flush', 'passage', 'hallway', 'ticket', 'entrance', 'room', 'yield', 'submit', 'challenge', 'boast', 'scorn', 'lean', 'rest', 'scrape', 'grate', 'refer', 'barrel', 'cask', 'bottle', 'box', 'case', 'nuisance', 'pest', 'garbage', 'relief', 'troublesome', 'rug', 'carpet', 'sofa', 'ottoman', 'hallway', 'tap', 'drain', 'boil', 'knock', 'rap', 'split', 'divided', 'crushed', 'grated', 'bruised', 'lump', 'chunk', 'stem', 'trunk', 'limb', 'outline', 'contour', 'pair', 'blend', 'block', 'swear', 'vow', 'explain', 'think', 'describe', 'relieved', 'rested', 'sleepy', 'tired', 'hasty', 'deserve', 'merit', 'need', 'want', 'expect', 'haste', 'a hurry', 'anger', 'ear', 'spite', 'stiff', 'firm', 'dark', 'drunk', 'cooked', 'verse', 'section', 'weed', 'twig', 'branch', 'steep', 'sheer', 'bare', 'rugged', 'stone', 'envious', 'jealous', 'enthusiastic ', 'hurt', 'relieved', 'paste', 'dough', 'syrup', 'block', 'jelly', 'scorn', 'refuse', 'enjoy', 'avoid', 'plan', 'refer', 'direct', 'call', 'carry', 'explain', 'limb', 'branch', 'bark ', 'trunk', 'twig', 'pad', 'cushion', 'board', 'block', 'tablet', 'boast', 'brag', 'yell', 'complain', 'explain', 'applause', 'approval', 'fear', 'shame', 'friends', 'sheet', 'leaf', 'book', 'block', 'tap', 'stem', 'stalk', 'bark', 'column', 'trunk', 'seize', 'take', 'refer', 'request', 'yield', 'trunk', 'chest', 'bag', 'closet', 'swing', 'weed', 'unwanted plant', 'cloth', 'animal', 'vegetable', 'approval', 'endorsement', 'gift', 'statement', 'confession', 'mass', 'lump', 'service', 'worship', 'element', 'swing', 'sway', 'bounce', 'break', 'crash', 'sore', 'painful', 'red', 'hot', 'rough', 'hinder', 'block', 'assist', 'relieve', 'yield', 'sticky', 'gooey', 'smooth', 'shiny', 'wet', 'confession', 'statement', 'service', 'plea', 'bargain']\n"
     ]
    }
   ],
   "source": [
    "#print(simlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get data from similarity file\n",
    "def get_sim_data(sim = simInputFile):\n",
    "    fin = open(sim, 'r')\n",
    "    qs = []\n",
    "    for line in fin:\n",
    "        q = [item.strip() for item in line.split('|')]\n",
    "        qs.append(q)\n",
    "    return qs\n",
    "\n",
    "#Check if all the words in the question exist in word dictionary\n",
    "def indict(q, worddict):\n",
    "    for w in q:\n",
    "        if(w not in worddict):\n",
    "            return False\n",
    "    return True\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity:  10.81081081081081 % accuracy\n",
      "Euclidean similarity:  13.513513513513514 % accuracy\n",
      "Manhattan similarity:  13.513513513513514 % accuracy\n"
     ]
    }
   ],
   "source": [
    "#Find cosine, euclidean and manhattan similarity. We are using scipy package for distance calculation\n",
    "\n",
    "def find_sim(sim = simInputFile, worddict = worddict):\n",
    "    qs = get_sim_data()\n",
    "    for q in qs:\n",
    "        if(not indict(q, worddict)):\n",
    "            qs.remove(q)\n",
    "    #print(qs, len(qs))\n",
    "    vec = [[(worddict[word]) for word in question ] for question in qs]\n",
    "    vec = [[[float(el) for el in vector] for vector in question] for question in vec]\n",
    "    cos = []\n",
    "    euclidean = []\n",
    "    manhattan = []\n",
    "    for q in vec:\n",
    "        dotp = []\n",
    "        dist1 = []\n",
    "        dist2 = []\n",
    "        q = np.array(q)\n",
    "        for i in range(1,5):\n",
    "            dotp.append(spatial.distance.cosine(q[0], q[i])) \n",
    "            dist1.append(spatial.distance.euclidean(q[0], q[i]))\n",
    "            dist2.append(spatial.distance.cityblock(q[0], q[i]))\n",
    "        dotp = np.array(dotp)\n",
    "        dist1 = np.array(dist1)\n",
    "        dist2 = np.array(dist2)\n",
    "        cos.append(np.argmax(dotp))\n",
    "        euclidean.append(np.argmax(dist1))\n",
    "        manhattan.append(np.argmax(dist2))\n",
    "    #vec = np.array(vec)\n",
    "    c1 = 0\n",
    "    c2 = 0\n",
    "    c3 = 0\n",
    "    for answer in cos:\n",
    "        if(answer==0):\n",
    "            c1 = c1 + 1\n",
    "    print(\"Cosine similarity: \", c1*100.0/len(cos),\"% accuracy\")\n",
    "    \n",
    "    for answer in euclidean:\n",
    "        if(answer==0):\n",
    "            c2 = c2 + 1\n",
    "    print(\"Euclidean similarity: \", c2*100.0/len(cos),\"% accuracy\")\n",
    "       \n",
    "    for answer in manhattan:\n",
    "        if(answer==0):\n",
    "            c3 = c3 + 1\n",
    "    print(\"Manhattan similarity: \", c3*100.0/len(cos),\"% accuracy\")\n",
    "    \n",
    "    #print(cos,'\\n', euclidean, '\\n', manhattan)\n",
    "find_sim()\n",
    "#get_sim_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
